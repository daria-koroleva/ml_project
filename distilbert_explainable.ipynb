{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd4752b",
   "metadata": {},
   "source": [
    "# DistilBERT for Phishing Email Detection\n",
    "\n",
    "This notebook demonstrates how to build and evaluate a transformer-based model (DistilBERT) for phishing email classification with comprehensive evaluation metrics.\n",
    "\n",
    "## Overview\n",
    "- **Model**: DistilBERT for sequence classification\n",
    "- **Dataset**: Phishing vs legitimate emails  \n",
    "- **Optimization**: 4 lightweight training strategies (reduced length, mixed precision, pruning, TinyBERT)\n",
    "- **Evaluation**: Comprehensive metrics (accuracy, precision, recall, F1-score, PR-AUC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb60d2",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25c038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME not installed. Install with: pip install lime\n",
      "SHAP not installed. Install with: pip install shap\n",
      "All libraries imported successfully!\n",
      "PyTorch version: 2.9.1+cpu\n",
      "CUDA available: False\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch and transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, \n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "# Sklearn for metrics and preprocessing\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, \n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Explainability libraries\n",
    "try:\n",
    "    import lime\n",
    "    from lime.lime_text import LimeTextExplainer\n",
    "    print(\"LIME imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"LIME not installed. Install with: pip install lime\")\n",
    "    \n",
    "try:\n",
    "    import shap\n",
    "    print(\"SHAP imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"SHAP not installed. Install with: pip install shap\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c921a",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bbf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loaded successfully from existing splits\n",
      "\n",
      " Dataset Overview:\n",
      "Train samples: 500\n",
      "Validation samples: 100\n",
      "Test samples: 100\n",
      "\n",
      "Class distribution in training set:\n",
      "label\n",
      "Phishing      261\n",
      "Legitimate    239\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Text length statistics:\n",
      "Mean: 1489 characters\n",
      "Median: 690 characters\n",
      "Max: 19690 characters\n",
      "\n",
      " Sample legitimate email:\n",
      "'re : fort pierce we can also potentially do a rofr without compromising our other sales efforts . . . - - - - - original message - - - - - from : kitchen , louise sent : wednesday , august 22 , 2001 5...'\n",
      "\n",
      "Sample phishing email:\n",
      "'Interesting mp3 Veronika Zemanova #UieHEQClaudia Schiffer Shocking mp3. #ZAFNLnThe video is Shocking! #ieHEQa More info...'\n",
      "\n",
      " Data prepared for model training!\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "try:\n",
    "    train_df = pd.read_csv(\"data/preprocessing/train.csv\")\n",
    "    val_df = pd.read_csv(\"data/preprocessing/val.csv\")\n",
    "    test_df = pd.read_csv(\"data/preprocessing/test.csv\")\n",
    "    print(\" Data loaded successfully from existing splits\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Preprocessed data not found. Loading raw data...\")\n",
    "\n",
    "SIMPLIFIED_TRAINING = True\n",
    "if SIMPLIFIED_TRAINING:\n",
    "    # keep only 5k samples for quicker experimentation\n",
    "    train_df = train_df.sample(n=500, random_state=42)\n",
    "    val_df = val_df.sample(n=100, random_state=42)\n",
    "    test_df = test_df.sample(n=100, random_state=42)\n",
    "# Combine subject and body text\n",
    "def combine_text(row):\n",
    "    subject = str(row['subject']) if pd.notna(row['subject']) else \"\"\n",
    "    body = str(row['body']) if pd.notna(row['body']) else \"\"\n",
    "    return f\"{subject} {body}\".strip()\n",
    "\n",
    "# Apply text combination to all datasets\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df['text'] = df.apply(combine_text, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Data overview\n",
    "print(\"\\n Dataset Overview:\")\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(train_df['label'].value_counts().rename({0: 'Legitimate', 1: 'Phishing'}))\n",
    "\n",
    "# Text length analysis\n",
    "train_df['text_length'] = train_df['text'].str.len()\n",
    "print(f\"\\nText length statistics:\")\n",
    "print(f\"Mean: {train_df['text_length'].mean():.0f} characters\")\n",
    "print(f\"Median: {train_df['text_length'].median():.0f} characters\")\n",
    "print(f\"Max: {train_df['text_length'].max()} characters\")\n",
    "\n",
    "# Show sample texts\n",
    "print(\"\\n Sample legitimate email:\")\n",
    "legit_sample = train_df[train_df['label'] == 0]['text'].iloc[0]\n",
    "print(f\"'{legit_sample[:200]}...'\")\n",
    "\n",
    "print(\"\\nSample phishing email:\")\n",
    "phish_sample = train_df[train_df['label'] == 1]['text'].iloc[0]\n",
    "print(f\"'{phish_sample[:200]}...'\")\n",
    "\n",
    "# Prepare data for model training\n",
    "X_train = train_df['text'].tolist()\n",
    "y_train = train_df['label'].tolist()\n",
    "X_val = val_df['text'].tolist()\n",
    "y_val = val_df['label'].tolist()\n",
    "X_test = test_df['text'].tolist()\n",
    "y_test = test_df['label'].tolist()\n",
    "\n",
    "print(f\"\\n Data prepared for model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6fabe5",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing for Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4976f",
   "metadata": {},
   "source": [
    "## 3.5 Optimization Options for Faster Training\n",
    "\n",
    "Choose ONE of the following lightweight approaches based on your needs:\n",
    "- **Option A**: DistilBERT with reduced sequence length (faster)\n",
    "- **Option B**: DistilBERT with mixed precision training (memory efficient)\n",
    "- **Option C**: DistilBERT with model pruning (smallest model)\n",
    "- **Option D**: TinyBERT (ultra-lightweight alternative)\n",
    "\n",
    "This section demonstrates all options. Uncomment your preferred approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c3b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OPTIMIZATION SETUP\n",
      "============================================================\n",
      "\n",
      "Available optimization strategies:\n",
      "  1. Reduced Sequence Length (Fastest - minimal quality loss)\n",
      "  2. Mixed Precision Training (Fast - uses fp16)\n",
      "  3. Model Pruning (Medium - removes less important weights)\n",
      "  4. TinyBERT Model (Smallest - alternative ultra-light model)\n",
      "\n",
      " Selected: Option 4\n",
      "============================================================\n",
      "\n",
      "Option 4: TinyBERT Model\n",
      "------------------------------------------------------------\n",
      " Model: TinyBERT (4 layers, 312 hidden dims)\n",
      " Base model: huawei-noah/TinyBERT_General_4L_312D\n",
      " Max sequence length: 128\n",
      " Batch size: 64\n",
      " Epochs: 3\n",
      "\n",
      "  Expected speedup: ~10x faster than DistilBERT\n",
      "  Model size: Only 14MB vs DistilBERT 250MB\n",
      " Quality impact: Acceptable (2-5% accuracy drop)\n",
      "\n",
      "Configuration ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZATION CONFIGURATION - preferred approach\n",
    "# ============================================================================\n",
    "\n",
    "# Set optimization preference here (1, 2, 3, or 4)\n",
    "OPTIMIZATION_CHOICE = 4  # 1=Reduced Length, 2=Mixed Precision, 3=Pruning, 4=TinyBERT\n",
    "\n",
    "print(\"MODEL OPTIMIZATION SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nAvailable optimization strategies:\")\n",
    "print(\"  1. Reduced Sequence Length (Fastest - minimal quality loss)\")\n",
    "print(\"  2. Mixed Precision Training (Fast - uses fp16)\")\n",
    "print(\"  3. Model Pruning (Medium - removes less important weights)\")\n",
    "print(\"  4. TinyBERT Model (Smallest - alternative ultra-light model)\")\n",
    "print(f\"\\n Selected: Option {OPTIMIZATION_CHOICE}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION 1: REDUCED SEQUENCE LENGTH (RECOMMENDED FOR FASTEST TRAINING)\n",
    "# ============================================================================\n",
    "if OPTIMIZATION_CHOICE == 1:\n",
    "    print(\"\\n Option 1: Reduced Sequence Length\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Use shorter max length - much faster without much quality loss\n",
    "    MAX_LENGTH = 128  # Reduced from 512 (4x faster!)\n",
    "    BATCH_SIZE = 32   # Can use larger batches with shorter sequences\n",
    "    LEARNING_RATE = 3e-4  # Slightly higher LR for shorter sequences\n",
    "    NUM_EPOCHS = 2    # Reduced epochs to save time\n",
    "    \n",
    "    print(f\" Max sequence length: {MAX_LENGTH} (reduced from 512)\")\n",
    "    print(f\" Batch size: {BATCH_SIZE}\")\n",
    "    print(f\" Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\" Epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"\\nExpected speedup: ~4-5x faster than full length\")\n",
    "    print(f\" Quality impact: Minimal (emails are usually concise)\")\n",
    "    \n",
    "    use_mixed_precision = False\n",
    "    use_pruning = False\n",
    "    tinybert = False\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION 2: MIXED PRECISION TRAINING (fp16)\n",
    "# ============================================================================\n",
    "elif OPTIMIZATION_CHOICE == 2:\n",
    "    print(\"\\nOption 2: Mixed Precision Training (FP16)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    MAX_LENGTH = 256   # Medium length\n",
    "    BATCH_SIZE = 48    # Larger batch size possible with fp16\n",
    "    LEARNING_RATE = 2e-4\n",
    "    NUM_EPOCHS = 2\n",
    "    \n",
    "    print(f\" Max sequence length: {MAX_LENGTH}\")\n",
    "    print(f\" Batch size: {BATCH_SIZE}\")\n",
    "    print(f\" Precision: Mixed (FP32 + FP16)\")\n",
    "    print(f\" Epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"\\nExpected speedup: ~2-3x faster + 50% less memory\")\n",
    "    print(f\"Quality impact: Negligible\")\n",
    "    \n",
    "    use_mixed_precision = True\n",
    "    use_pruning = False\n",
    "    tinybert = False\n",
    "    \n",
    "    # Install apex if using NVIDIA GPU for better mixed precision\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"\\nFor best mixed precision performance on GPU:\")\n",
    "            print(\"   pip install apex\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION 3: MODEL PRUNING (Remove 30% of less important weights)\n",
    "# ============================================================================\n",
    "elif OPTIMIZATION_CHOICE == 3:\n",
    "    print(\"\\n Option 3: Model Pruning\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    MAX_LENGTH = 256\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 2e-4\n",
    "    NUM_EPOCHS = 2\n",
    "    PRUNING_AMOUNT = 0.3  # Remove 30% of weights\n",
    "    \n",
    "    print(f\" Max sequence length: {MAX_LENGTH}\")\n",
    "    print(f\" Batch size: {BATCH_SIZE}\")\n",
    "    print(f\" Pruning amount: {PRUNING_AMOUNT*100:.0f}% of weights\")\n",
    "    print(f\" Epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"\\nExpected speedup: ~2-3x faster + 30% smaller model\")\n",
    "    print(f\" Quality impact: Very small (1-2% accuracy drop)\")\n",
    "    \n",
    "    use_mixed_precision = False\n",
    "    use_pruning = True\n",
    "    tinybert = False\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION 4: TinyBERT (Ultra-lightweight alternative)\n",
    "# ============================================================================\n",
    "elif OPTIMIZATION_CHOICE == 4:\n",
    "    print(\"\\nOption 4: TinyBERT Model\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    model_name = \"huawei-noah/TinyBERT_General_4L_312D\"  # 4 layers, 312 dims\n",
    "    MAX_LENGTH = 128\n",
    "    BATCH_SIZE = 64   # TinyBERT is so light you can use huge batches\n",
    "    LEARNING_RATE = 3e-4\n",
    "    NUM_EPOCHS = 3\n",
    "    \n",
    "    print(f\" Model: TinyBERT (4 layers, 312 hidden dims)\")\n",
    "    print(f\" Base model: {model_name}\")\n",
    "    print(f\" Max sequence length: {MAX_LENGTH}\")\n",
    "    print(f\" Batch size: {BATCH_SIZE}\")\n",
    "    print(f\" Epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"\\n  Expected speedup: ~10x faster than DistilBERT\")\n",
    "    print(f\"  Model size: Only 14MB vs DistilBERT 250MB\")\n",
    "    print(f\" Quality impact: Acceptable (2-5% accuracy drop)\")\n",
    "    \n",
    "    use_mixed_precision = False\n",
    "    use_pruning = False\n",
    "    tinybert = True\n",
    "\n",
    "else:\n",
    "    print(\"Invalid choice. Using Option 1 (Reduced Sequence Length)\")\n",
    "    MAX_LENGTH = 128\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 3e-4\n",
    "    NUM_EPOCHS = 2\n",
    "    use_mixed_precision = False\n",
    "    use_pruning = False\n",
    "    tinybert = False\n",
    "\n",
    "print(\"\\nConfiguration ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2aafd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      " Train dataset: 500 samples\n",
      " Validation dataset: 100 samples\n",
      " Test dataset: 100 samples\n",
      "\n",
      "Tokenization example:\n",
      "Original text: 're : fort pierce we can also potentially do a rofr without compromising our other sales efforts . . '\n",
      "Token IDs shape: torch.Size([1, 50])\n",
      "First 10 token IDs: [101, 2128, 1024, 3481, 9267, 2057, 2064, 2036, 9280, 2079]\n",
      "Decoded tokens: ['[CLS]', 're', ':', 'fort', 'pierce', 'we', 'can', 'also', 'potentially', 'do']\n",
      "\n",
      "Token length statistics (sample):\n",
      "Mean tokens: 400.9\n",
      "95th percentile: 1330\n",
      "Texts that would be truncated at 128: 311 (62.2%)\n"
     ]
    }
   ],
   "source": [
    "# Initialize DistilBERT tokenizer\n",
    "if not tinybert:\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "# model_name already set if using TinyBERT option\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# MAX_LENGTH is now configured in optimization section above\n",
    "\n",
    "class EmailDataset(Dataset):\n",
    "    \"\"\"Custom dataset class for email classification\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=MAX_LENGTH):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = EmailDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = EmailDataset(X_val, y_val, tokenizer)\n",
    "test_dataset = EmailDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "print(f\" Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\" Validation dataset: {len(val_dataset)} samples\") \n",
    "print(f\" Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "# Test tokenization on a sample\n",
    "sample_text = X_train[0][:100]  # First 100 chars\n",
    "sample_encoding = tokenizer(\n",
    "    sample_text,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    max_length=min(50, MAX_LENGTH),  # Smaller for display\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "print(f\"\\nTokenization example:\")\n",
    "print(f\"Original text: '{sample_text}'\")\n",
    "print(f\"Token IDs shape: {sample_encoding['input_ids'].shape}\")\n",
    "print(f\"First 10 token IDs: {sample_encoding['input_ids'][0][:10].tolist()}\")\n",
    "print(f\"Decoded tokens: {tokenizer.convert_ids_to_tokens(sample_encoding['input_ids'][0][:10])}\")\n",
    "\n",
    "# Analyze text lengths after tokenization\n",
    "sample_lengths = []\n",
    "for text in X_train[:1000]:  # Sample first 1000 for speed\n",
    "    tokens = tokenizer(text, truncation=False, return_tensors='pt')\n",
    "    sample_lengths.append(tokens['input_ids'].shape[1])\n",
    "\n",
    "print(f\"\\nToken length statistics (sample):\")\n",
    "print(f\"Mean tokens: {np.mean(sample_lengths):.1f}\")\n",
    "print(f\"95th percentile: {np.percentile(sample_lengths, 95):.0f}\")\n",
    "print(f\"Texts that would be truncated at {MAX_LENGTH}: {sum(1 for x in sample_lengths if x > MAX_LENGTH)} ({sum(1 for x in sample_lengths if x > MAX_LENGTH)/len(sample_lengths)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b7162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model name: huawei-noah/TinyBERT_General_4L_312D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model loaded: DistilBertForSequenceClassification\n",
      " Number of parameters: 19,030,250\n",
      " Trainable parameters: 19,030,250\n",
      " Model size: 72.6 MB\n",
      "\n",
      " Trainer initialized successfully!\n",
      "\n",
      " Optimized Training Configuration:\n",
      "  - Model: huawei-noah/TinyBERT_General_4L_312D\n",
      "  - Epochs: 3\n",
      "  - Batch size: 64\n",
      "  - Max length: 128\n",
      "  - Learning rate: 0.0003\n",
      "  - Mixed precision: False\n",
      "  - Warmup steps: 50\n",
      "\n",
      " Training method: Hugging Face Trainer\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model based on optimization choice\n",
    "print(\"Loading model...\")\n",
    "print(f\"Model name: {model_name}\")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,  # Binary classification: phishing vs legitimate\n",
    "    output_attentions=True,  # Enable attention weights for explainability\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Apply model pruning if selected\n",
    "if use_pruning:\n",
    "    print(\"\\nApplying model pruning...\")\n",
    "    from torch.nn.utils.prune import global_unstructured, remove\n",
    "    \n",
    "    # Get all model parameters\n",
    "    parameters_to_prune = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "    \n",
    "    if parameters_to_prune:\n",
    "        # Apply global pruning\n",
    "        global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method=torch.nn.utils.prune.L1Unstructured,\n",
    "            amount=PRUNING_AMOUNT\n",
    "        )\n",
    "        \n",
    "        # Remove pruning reparameterization\n",
    "        for module, name in parameters_to_prune:\n",
    "            remove(module, name)\n",
    "        \n",
    "        print(f\" Pruned {PRUNING_AMOUNT*100:.0f}% of weights\")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"\\n Model loaded: {model.__class__.__name__}\")\n",
    "print(f\" Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\" Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Calculate model size in MB\n",
    "model_size = sum(p.numel() for p in model.parameters()) * 4 / (1024**2)\n",
    "print(f\" Model size: {model_size:.1f} MB\")\n",
    "\n",
    "# Try to use Trainer with optimizations\n",
    "try:\n",
    "    from transformers import TrainingArguments, Trainer\n",
    "    \n",
    "    # Define training arguments with optimizations\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./models/distilbert-phishing\",\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "        warmup_steps=50,  # Reduced warmup\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=20,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,  # Evaluate less frequently\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=200,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_f1\",\n",
    "        greater_is_better=True,\n",
    "        seed=42,\n",
    "        dataloader_pin_memory=False,\n",
    "        remove_unused_columns=False,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        # Optimization flags\n",
    "        fp16=use_mixed_precision,  # Enable mixed precision\n",
    "        optim=\"adamw_torch\",  # Efficient optimizer\n",
    "        gradient_checkpointing=True,  # Trade compute for memory\n",
    "    )\n",
    "\n",
    "    # Define metrics computation function\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    print(\"\\n Trainer initialized successfully!\")\n",
    "    print(f\"\\n Optimized Training Configuration:\")\n",
    "    print(f\"  - Model: {model_name}\")\n",
    "    print(f\"  - Epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"  - Max length: {MAX_LENGTH}\")\n",
    "    print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"  - Mixed precision: {use_mixed_precision}\")\n",
    "    if use_pruning:\n",
    "        print(f\"  - Pruning: {PRUNING_AMOUNT*100:.0f}%\")\n",
    "    print(f\"  - Warmup steps: 50\")\n",
    "    \n",
    "    use_trainer = True\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"\\n Trainer import failed: {str(e)}\")\n",
    "    print(\" Will use manual training instead...\")\n",
    "    use_trainer = False\n",
    "\n",
    "print(f\"\\n Training method: {'Hugging Face Trainer' if use_trainer else 'Manual PyTorch'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f94aff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current accelerate version: 1.12.0\n",
      " Trainer imported successfully!\n",
      "Transformers version: 4.57.1\n",
      " All training components imported successfully!\n",
      "Ready to proceed with training!\n"
     ]
    }
   ],
   "source": [
    "# Check accelerate version for Trainer compatibility\n",
    "try:\n",
    "    import accelerate\n",
    "    print(f\"Current accelerate version: {accelerate.__version__}\")\n",
    "    \n",
    "    # Try importing Trainer to see if it works\n",
    "    from transformers import Trainer\n",
    "    print(\" Trainer imported successfully!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    if \"accelerate\" in str(e):\n",
    "        print(f\"Accelerate import error: {str(e)}\")\n",
    "        print(\"Trying to fix accelerate installation...\")\n",
    "        \n",
    "        # Try to install/upgrade accelerate\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"accelerate>=0.26.0\"])\n",
    "            print(\" Accelerate upgraded successfully!\")\n",
    "            \n",
    "            # Try importing again\n",
    "            import accelerate\n",
    "            from transformers import Trainer\n",
    "            print(f\" Now using accelerate version: {accelerate.__version__}\")\n",
    "            \n",
    "        except Exception as install_error:\n",
    "            print(f\"Failed to fix accelerate: {str(install_error)}\")\n",
    "            print(\"Manual fix needed: pip install --upgrade 'accelerate>=0.26.0'\")\n",
    "    else:\n",
    "        print(f\"Other import error: {str(e)}\")\n",
    "\n",
    "# Also check transformers version\n",
    "import transformers\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "\n",
    "# Try importing all required components\n",
    "try:\n",
    "    from transformers import TrainingArguments, Trainer\n",
    "    print(\" All training components imported successfully!\")\n",
    "    trainer_available = True\n",
    "except ImportError as e:\n",
    "    print(f\"Training components import failed: {str(e)}\")\n",
    "    trainer_available = False\n",
    "\n",
    "if trainer_available:\n",
    "    print(\"Ready to proceed with training!\")\n",
    "else:\n",
    "    print(\"Training may not work. Please restart kernel and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157c439",
   "metadata": {},
   "source": [
    "## 4. Create DistilBERT Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8c758",
   "metadata": {},
   "source": [
    "## 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading pre-trained model...\n",
      " Pre-trained model loaded successfully!\n",
      "\n",
      " Model training summary:\n",
      " Model successfully trained and loaded\n",
      " Model location: models\\distilbert-phishings\n",
      " Max sequence length: 128\n",
      " Batch size used: 64\n",
      " Ready for evaluation and explainability analysis\n"
     ]
    }
   ],
   "source": [
    "# Check if pre-trained model exists\n",
    "model_save_path = Path(\"./models/distilbert-phishing\")\n",
    "model_exists = model_save_path.exists() and any(model_save_path.glob(\"*.bin\")) or any(model_save_path.glob(\"*.safetensors\"))\n",
    "\n",
    "if model_exists:\n",
    "    print(\"Loading pre-trained model...\")\n",
    "    try:\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(\n",
    "            model_save_path,\n",
    "            output_attentions=True\n",
    "        ).to(device)\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(model_save_path)\n",
    "        print(\"Pre-trained model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {e}\")\n",
    "        print(\"Will train a new model instead...\")\n",
    "        model_exists = False\n",
    "\n",
    "if not model_exists:\n",
    "    print(\"Training new model...\")\n",
    "    \n",
    "    if use_trainer:\n",
    "        # Use Hugging Face Trainer\n",
    "        try:\n",
    "            print(\"\\nTraining started...\")\n",
    "            trainer.train()\n",
    "            print(\"Training completed successfully!\")\n",
    "            \n",
    "            # Save the best model\n",
    "            trainer.save_model()\n",
    "            tokenizer.save_pretrained(training_args.output_dir)\n",
    "            print(f\"Model saved to {training_args.output_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Trainer failed: {str(e)}\")\n",
    "            print(\"Switching to manual training...\")\n",
    "            use_trainer = False\n",
    "    \n",
    "    if not use_trainer:\n",
    "        # Manual training loop with optimizations\n",
    "        print(\"Starting manual training...\")\n",
    "        \n",
    "        from torch.optim import AdamW\n",
    "        from torch.utils.data import DataLoader\n",
    "        \n",
    "        # Create data loaders with optimized batch size\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Setup optimizer with optimized learning rate\n",
    "        optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "            total_loss = 0\n",
    "            \n",
    "            for batch_idx, batch in enumerate(train_dataloader):\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(input_ids=input_ids, \n",
    "                              attention_mask=attention_mask, \n",
    "                              labels=labels)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Print progress\n",
    "                if batch_idx % 20 == 0 and batch_idx > 0:\n",
    "                    avg_loss = total_loss / (batch_idx + 1)\n",
    "                    print(f\"  Batch {batch_idx}/{len(train_dataloader)}, Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            avg_loss = total_loss / len(train_dataloader)\n",
    "            print(f\"  Average Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            # Validation every epoch\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_dataloader:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['labels'].to(device)\n",
    "                    \n",
    "                    outputs = model(input_ids=input_ids, \n",
    "                                  attention_mask=attention_mask, \n",
    "                                  labels=labels)\n",
    "                    val_loss += outputs.loss.item()\n",
    "                    \n",
    "                    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "                    val_correct += (predictions == labels).sum().item()\n",
    "                    val_total += labels.size(0)\n",
    "            \n",
    "            val_accuracy = val_correct / val_total\n",
    "            print(f\"  Validation Loss: {val_loss/len(val_dataloader):.4f}\")\n",
    "            print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "            \n",
    "            model.train()\n",
    "        \n",
    "        # Save manually trained model\n",
    "        model_save_path.mkdir(parents=True, exist_ok=True)\n",
    "        model.save_pretrained(model_save_path)\n",
    "        tokenizer.save_pretrained(model_save_path)\n",
    "        print(f\"\\n✓ Training completed! Model saved to {model_save_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Model: {model.__class__.__name__}\")\n",
    "print(f\"✓ Location: {model_save_path}\")\n",
    "print(f\"✓ Max sequence length: {MAX_LENGTH}\")\n",
    "print(f\"✓ Ready for evaluation\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07490c4b",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dc0e386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n",
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9700\n",
      "Precision: 0.9702\n",
      "Recall:    0.9700\n",
      "F1-Score:  0.9700\n",
      "PR-AUC:    0.9991\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.96      0.98      0.97        53\n",
      "    Phishing       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.97       100\n",
      "   macro avg       0.97      0.97      0.97       100\n",
      "weighted avg       0.97      0.97      0.97       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[52  1]\n",
      " [ 2 45]]\n",
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9700\n",
      "Precision: 0.9702\n",
      "Recall:    0.9700\n",
      "F1-Score:  0.9700\n",
      "PR-AUC:    0.9991\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.96      0.98      0.97        53\n",
      "    Phishing       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.97       100\n",
      "   macro avg       0.97      0.97      0.97       100\n",
      "weighted avg       0.97      0.97      0.97       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[52  1]\n",
      " [ 2 45]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# Create evaluation pipeline with proper max_length handling\n",
    "class MaxLengthPipeline:\n",
    "    \"\"\"Wrapper to handle max_length in pipeline\"\"\"\n",
    "    def __init__(self, base_pipeline, max_length):\n",
    "        self.pipe = base_pipeline\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __call__(self, texts, batch_size=None):\n",
    "        \"\"\"Handle both single texts and batches\"\"\"\n",
    "        # Ensure texts is a list\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        # Truncate texts to avoid sequence length mismatch\n",
    "        # Rough estimate: ~4 characters per token\n",
    "        max_chars = self.max_length * 4\n",
    "        truncated_texts = []\n",
    "        for text in texts:\n",
    "            if len(text) > max_chars:\n",
    "                text = text[:max_chars]\n",
    "            truncated_texts.append(text)\n",
    "        \n",
    "        # Call the underlying pipeline\n",
    "        return self.pipe(truncated_texts, batch_size=batch_size)\n",
    "\n",
    "# Create base pipeline\n",
    "base_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Wrap it with max_length handling\n",
    "eval_pipeline = MaxLengthPipeline(base_pipeline, MAX_LENGTH)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_predictions = []\n",
    "test_probabilities = []\n",
    "\n",
    "# Batch prediction for efficiency\n",
    "batch_size = 32\n",
    "for i in range(0, len(X_test), batch_size):\n",
    "    batch_texts = X_test[i:i + batch_size]\n",
    "    batch_results = eval_pipeline(batch_texts)\n",
    "    \n",
    "    for result in batch_results:\n",
    "        # Handle both nested list and flat list formats\n",
    "        if isinstance(result, list):  # Nested list: [[{...}, {...}], ...]\n",
    "            # Extract the scores from the nested list\n",
    "            scores = {r['label']: r['score'] for r in result}\n",
    "            phishing_score = scores.get('LABEL_1', 0.0)\n",
    "        else:  # Single dict: {...}\n",
    "            phishing_score = result['score'] if result['label'] == 'LABEL_1' else 1 - result['score']\n",
    "        \n",
    "        prediction = 1 if phishing_score > 0.5 else 0\n",
    "        test_predictions.append(prediction)\n",
    "        test_probabilities.append(phishing_score)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_pred = np.array(test_predictions)\n",
    "y_prob = np.array(test_probabilities)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "pr_auc = average_precision_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"PR-AUC:    {pr_auc:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Phishing']))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=['Legitimate', 'Phishing'],\n",
    "           yticklabels=['Legitimate', 'Phishing'],\n",
    "           ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_prob)\n",
    "axes[1].plot(recall_curve, precision_curve, marker='.', linewidth=2, label=f'PR-AUC = {pr_auc:.4f}')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEvaluation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15c2ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and results...\n",
      "Model already exists at models\\distilbert-phishing\n",
      "✓ Results saved to results\\model_results.json\n",
      "✓ Predictions saved to results\\predictions.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "✓ Model trained: huawei-noah/TinyBERT_General_4L_312D\n",
      "✓ Optimization: Option 4\n",
      "✓ Max sequence length: 128\n",
      "✓ Test accuracy: 0.9700\n",
      "✓ Test F1-Score: 0.9700\n",
      "\n",
      "Files saved:\n",
      "  - Model: models\\distilbert-phishing\n",
      "  - Results: results\\model_results.json\n",
      "  - Predictions: results\\predictions.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save Model and Results\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Saving model and results...\")\n",
    "\n",
    "# Create results directory\n",
    "results_dir = Path(\"results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save model and tokenizer\n",
    "model_dir = Path(\"models/distilbert-phishing\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(model_dir)\n",
    "    tokenizer.save_pretrained(model_dir)\n",
    "    print(f\"Model saved to {model_dir}\")\n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n",
    "\n",
    "# Save evaluation results\n",
    "results = {\n",
    "    \"model_info\": {\n",
    "        \"model_name\": model_name,\n",
    "        \"architecture\": \"DistilBERT for sequence classification\",\n",
    "        \"num_parameters\": int(sum(p.numel() for p in model.parameters())),\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "        \"training_date\": datetime.now().isoformat()\n",
    "    },\n",
    "    \"dataset_info\": {\n",
    "        \"train_size\": len(X_train),\n",
    "        \"val_size\": len(X_val), \n",
    "        \"test_size\": len(X_test),\n",
    "        \"class_distribution\": {\n",
    "            \"legitimate\": int(sum(1 for x in y_train if x == 0)),\n",
    "            \"phishing\": int(sum(1 for x in y_train if x == 1))\n",
    "        }\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"test_accuracy\": float(accuracy),\n",
    "        \"test_precision\": float(precision),\n",
    "        \"test_recall\": float(recall),\n",
    "        \"test_f1_score\": float(f1),\n",
    "        \"test_pr_auc\": float(pr_auc)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "results_file = results_dir / \"model_results.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"✓ Results saved to {results_file}\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'text': X_test,\n",
    "    'true_label': y_test,\n",
    "    'predicted_label': y_pred,\n",
    "    'phishing_probability': y_prob,\n",
    "    'correct_prediction': y_test == y_pred\n",
    "})\n",
    "\n",
    "predictions_file = results_dir / \"predictions.csv\"\n",
    "predictions_df.to_csv(predictions_file, index=False)\n",
    "print(f\"✓ Predictions saved to {predictions_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Model trained: {model_name}\")\n",
    "print(f\"✓ Optimization: Option {OPTIMIZATION_CHOICE}\")\n",
    "print(f\"✓ Max sequence length: {MAX_LENGTH}\")\n",
    "print(f\"✓ Test accuracy: {accuracy:.4f}\")\n",
    "print(f\"✓ Test F1-Score: {f1:.4f}\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - Model: {model_dir}\")\n",
    "print(f\"  - Results: {results_file}\")\n",
    "print(f\"  - Predictions: {predictions_file}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abec6c3",
   "metadata": {},
   "source": [
    "## 10. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fab49b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saving model and results...\n",
      " Model already exists at models\\distilbert-phishing\n",
      "Results saved to results\\distilbert_results.json\n",
      "Predictions saved to results\\distilbert_predictions.csv\n",
      "Inference function saved to results\\classify_email_function.pkl\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE!\n",
      "============================================================\n",
      "Model Performance Summary:\n",
      "Accuracy: 0.9700\n",
      "F1-Score: 0.9700\n",
      "PR-AUC: 0.9991\n",
      "\n",
      "Saved Files:\n",
      "Model: models\\distilbert-phishing\n",
      "Results: results\\distilbert_results.json\n",
      "Predictions: results\\distilbert_predictions.csv\n",
      "\n",
      "DistilBERT phishing detection model is ready!\n",
      "============================================================\n",
      "\n",
      "Testing saved model on sample phishing email:\n",
      "Sample: 'Get 50% off PS5! Click here now for amazing deals!'\n",
      "Prediction: Phishing (confidence: 0.997)\n"
     ]
    }
   ],
   "source": [
    "# Save model, tokenizer, and results\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\" Saving model and results...\")\n",
    "\n",
    "# Create results directory\n",
    "results_dir = Path(\"results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save model and tokenizer (if not already saved)\n",
    "model_dir = Path(\"models/distilbert-phishing\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(model_dir)\n",
    "    tokenizer.save_pretrained(model_dir)\n",
    "    print(f\" Model saved to {model_dir}\")\n",
    "else:\n",
    "    print(f\" Model already exists at {model_dir}\")\n",
    "\n",
    "# Save evaluation results\n",
    "results = {\n",
    "    \"model_info\": {\n",
    "        \"model_name\": model_name,\n",
    "        \"architecture\": \"DistilBERT for sequence classification\",\n",
    "        \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "        \"training_date\": datetime.now().isoformat()\n",
    "    },\n",
    "    \"dataset_info\": {\n",
    "        \"train_size\": len(X_train),\n",
    "        \"val_size\": len(X_val), \n",
    "        \"test_size\": len(X_test),\n",
    "        \"class_distribution\": {\n",
    "            \"legitimate\": int(sum(1 for x in y_train if x == 0)),\n",
    "            \"phishing\": int(sum(1 for x in y_train if x == 1))\n",
    "        }\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"test_accuracy\": float(accuracy),\n",
    "        \"test_precision\": float(precision),\n",
    "        \"test_recall\": float(recall),\n",
    "        \"test_f1_score\": float(f1),\n",
    "        \"test_pr_auc\": float(pr_auc)\n",
    "    },\n",
    "    \"training_config\": {\n",
    "        \"epochs\": training_args.num_train_epochs,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"warmup_steps\": training_args.warmup_steps,\n",
    "        \"weight_decay\": training_args.weight_decay\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "results_file = results_dir / \"distilbert_results.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {results_file}\")\n",
    "\n",
    "# Save predictions for further analysis\n",
    "predictions_df = pd.DataFrame({\n",
    "    'text': X_test,\n",
    "    'true_label': y_test,\n",
    "    'predicted_label': y_pred,\n",
    "    'phishing_probability': y_prob,\n",
    "    'correct_prediction': y_test == y_pred\n",
    "})\n",
    "\n",
    "predictions_file = results_dir / \"distilbert_predictions.csv\"\n",
    "predictions_df.to_csv(predictions_file, index=False)\n",
    "print(f\"Predictions saved to {predictions_file}\")\n",
    "\n",
    "# Create a simple inference function for future use\n",
    "def classify_email(text, model_path=\"models/distilbert-phishing\"):\n",
    "    \"\"\"\n",
    "    Classify a single email text using the trained DistilBERT model\n",
    "    \n",
    "    Args:\n",
    "        text (str): Email text to classify\n",
    "        model_path (str): Path to the saved model\n",
    "    \n",
    "    Returns:\n",
    "        dict: Classification results with prediction and confidence\n",
    "    \"\"\"\n",
    "    # Create pipeline with max_length handling\n",
    "    classifier = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_all_scores=True\n",
    "    )\n",
    "    \n",
    "    # Make prediction\n",
    "    results = classifier(text)\n",
    "    \n",
    "    # Handle both nested list and flat list formats\n",
    "    if isinstance(results[0], list):\n",
    "        # Nested list format: [[{...}, {...}]]\n",
    "        scores = {r['label']: r['score'] for r in results[0]}\n",
    "        phishing_score = scores.get('LABEL_1', 0.0)\n",
    "    else:\n",
    "        # Flat list format: [{...}, {...}]\n",
    "        scores = {r['label']: r['score'] for r in results}\n",
    "        phishing_score = scores.get('LABEL_1', 0.0)\n",
    "    \n",
    "    prediction = \"Phishing\" if phishing_score > 0.5 else \"Legitimate\"\n",
    "    confidence = phishing_score if prediction == \"Phishing\" else 1 - phishing_score\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": prediction,\n",
    "        \"confidence\": confidence,\n",
    "        \"phishing_probability\": phishing_score,\n",
    "        \"legitimate_probability\": 1 - phishing_score\n",
    "    }\n",
    "\n",
    "# Save the inference function\n",
    "import pickle\n",
    "with open(results_dir / \"classify_email_function.pkl\", \"wb\") as f:\n",
    "    pickle.dump(classify_email, f)\n",
    "\n",
    "print(f\"Inference function saved to {results_dir / 'classify_email_function.pkl'}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model Performance Summary:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "print(f\"\\nSaved Files:\")\n",
    "print(f\"Model: {model_dir}\")\n",
    "print(f\"Results: {results_file}\")\n",
    "print(f\"Predictions: {predictions_file}\")\n",
    "print(f\"\\nDistilBERT phishing detection model is ready!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example usage of the saved model\n",
    "print(f\"\\nTesting saved model on sample phishing email:\")\n",
    "sample_text = \"Get 50% off PS5! Click here now for amazing deals!\"\n",
    "result = classify_email(sample_text)\n",
    "print(f\"Sample: '{sample_text}'\")\n",
    "print(f\"Prediction: {result['prediction']} (confidence: {result['confidence']:.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
